{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6166efcb-b7f8-424b-8015-cb646a764271",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Embedding Text with local (per node) NVIDIA TensorRT accelerator and GPU based Aproximate Nearest Neighbor (ANN)\n",
    "\n",
    "The demo extending existing [Azure OpenAI based demo](https://github.com/microsoft/SynapseML/blob/master/docs/Explore%20Algorithms/OpenAI/Quickstart%20-%20OpenAI%20Embedding%20and%20GPU%20based%20KNN.ipynb) when encoding is processed by OpenAI requests and KNN was using GPU based brute force search. This tutorial shows how to perform fast local embeddings using [multilingual E5 text embeddings](https://arxiv.org/abs/2402.05672) and fast aproximate Nearest Neighbor search using IVFFlat alcorithm. All tutorial stages accelerated by NVIDIA GPU using [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt) and [Spark Rapids ML](https://github.com/NVIDIA/spark-rapids-ml). The tutorial folder contains two benchmark notebooks to demonstrate advantages of the presented GPU based approach compare to [previos CPU based demo](https://github.com/microsoft/SynapseML/blob/master/docs/Explore%20Algorithms/OpenAI/Quickstart%20-%20OpenAI%20Embedding.ipynb)\n",
    "\n",
    "The key prerequisites for this quickstart include a working Azure OpenAI resource, and an Apache Spark cluster with SynapseML installed. We suggest creating a Synapse workspace, but currently the notebook was running on Databricks GPU based cluster using Standard_NC24ads_A100_v4 with 6 workers. Databricks Runtime was 13.3 LTS ML (includes Apache Spark 3.4.1, GPU, Scala 2.12) with related [init_script](https://github.com/microsoft/SynapseML/tree/master/tools/init_scripts) to install all required packages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0444a03d-a701-4f59-b1a1-c4addb797d07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 1: Prepare Environment\n",
    "\n",
    "It will imports required libraries and get initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d188d8ee-8913-4170-8d35-8490f833ae95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import pyspark.sql.functions as F\n",
    "from synapse.ml.HuggingFaceSentenceEmbedder import HuggingFaceSentenceEmbedder\n",
    "from pyspark.sql.types import (\n",
    "     StructType,\n",
    "     StructField,\n",
    "     IntegerType,\n",
    "     StringType\n",
    ")\n",
    "from spark_rapids_ml.knn import (\n",
    "    ApproximateNearestNeighbors,\n",
    "    ApproximateNearestNeighborsModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42117315-a245-491a-b330-f8257d6fb35c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 2: Load Input Data\n",
    "\n",
    "It will load public dataset and generate extra syntetic rows if set by size parameter\n",
    "\n",
    "The loaded dataset has 1000 rows. If you specify <i>number_of_input_rows</i> in [1..1000] it will cut extra rows if needed\n",
    "\n",
    "If <i>number_of_input_rows</i> in [1000..1000000] it will generate extra rows using cross join of original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b6bdb2c-d492-4114-a7e9-0ef2832ac05c",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"wasbs://publicwasb@mmlspark.blob.core.windows.net/fine_food_reviews_1k.csv\"\n",
    "\n",
    "df = spark.read.options(inferSchema=\"True\", delimiter=\",\", header=True).csv(\n",
    "    file_path\n",
    ")\n",
    "df = df.withColumn(\n",
    "    \"data\",\n",
    "    F.format_string(\n",
    "        \"Title: %s; Content: %s\", F.trim(df.Summary), F.trim(df.Text)\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Size of DF\n",
    "number_of_input_rows = 100\n",
    "\n",
    "\n",
    "# Check if the row count is less than 10\n",
    "if number_of_input_rows <= 0 or number_of_input_rows >= 1000000:\n",
    "    raise ValueError(f\"Limit is {number_of_input_rows}, which should be less than 1M.\")\n",
    "\n",
    "if number_of_input_rows > 1000:\n",
    "\n",
    "    # Cross-join the DataFrame with itself to create n x n pairs for string concatenation (synthetic data)\n",
    "    cross_joined_df = df.crossJoin(\n",
    "        df.withColumnRenamed(\"data\", \"data_\")\n",
    "    )\n",
    "\n",
    "    # Create a new column 'result_vector' by concatenating the two source vectors\n",
    "    tmp_df = cross_joined_df.withColumn(\n",
    "        \"result_vector\",\n",
    "        F.concat(F.col(\"data\"), F.lit(\". \\n\"), F.col(\"data_\")),\n",
    "    )\n",
    "\n",
    "    # Select only the necessary columns and show the result\n",
    "    tmp_df = tmp_df.select(\"result_vector\")\n",
    "\n",
    "    # Shuffle the DataFrame with a fixed seed to have close strings spreaded\n",
    "    seed = 42\n",
    "\n",
    "    df = tmp_df.withColumnRenamed(\"result_vector\", \"data\").withColumn(\n",
    "        \"id\", F.monotonically_increasing_id()).orderBy(F.rand(seed))\n",
    "    \n",
    "\n",
    "df = df.limit(number_of_input_rows).repartition(10).cache()\n",
    "\n",
    "print(f\"Loaded: {number_of_input_rows} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c69ee56-172f-413b-a335-d15482fda55e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 3: Generate Embeddings\n",
    "\n",
    "We will first generate embeddings using NVIDIA TensorRT optimized SentenceTransformer. In the demo you can use two fifferent HF models: intfloat/e5-large-v2 or sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d7bd9db-79a1-4d46-a849-ac49c3de7b49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To create embedder with different models, uncomment the following line\n",
    "# embedder = HuggingFaceSentenceEmbedder(modelName=\"intfloat/e5-large-v2\", inputCol=\"combined\", outputCol=\"embeddings\", runtime=\"tensorrt\")\n",
    "embedder = HuggingFaceSentenceEmbedder(modelName=\"sentence-transformers/all-MiniLM-L6-v2\", inputCol=\"data\", outputCol=\"embeddings\", runtime=\"tensorrt\")\n",
    "\n",
    "embeddings = embedder.transform(df).select(\"id\", \"embeddings\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6885033f-6eea-4338-a632-2837582d91a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 4: Build the query against embeddings\n",
    "\n",
    "Get query embeddings running standard SentenceTransformer just on the driver. Convert embedding results to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b83621-3f42-42ff-847e-97a4af2d3276",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample query\n",
    "queries = [\"desserts\", \"disgusting\"]\n",
    "ids = [1, 2]\n",
    "\n",
    "# Create DataFrame directly from the data and schema\n",
    "qDf = spark.createDataFrame(\n",
    "    list(zip(ids, queries)),\n",
    "    StructType([\n",
    "        StructField(\"id\", IntegerType(), nullable=False),\n",
    "        StructField(\"data\", StringType(), nullable=False)\n",
    "    ])\n",
    ")\n",
    "\n",
    "query_embeddings = embedder.transform(qDf).select(\"id\", \"embeddings\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0154ce06-5875-4236-8178-030d45091445",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 5: Build a fast vector index to over review embeddings\n",
    "\n",
    "We will use fast NVIDIA Rapids indexer. This KNN implementation will work only on GPU. If you want to use CPU then switch to synapse.ml.nn CPU based KNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c01d2c1e-837b-4525-a4d3-4938fd4221fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available. Terminating the notebook.\")\n",
    "    try:\n",
    "        sys.exit()\n",
    "    except SystemExit:\n",
    "        print(\"Notebook termination prevented by exception handling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa0e4178-75e4-412b-940e-25d55b7396ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rapids_knn_model = (ApproximateNearestNeighbors(k=5)\n",
    "                    .setInputCol(\"embeddings\")\n",
    "                    .setIdCol(\"id\")\n",
    "                    .fit(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "521c9c8e-6422-49c7-95f3-6bca44a90cbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 6: Find top k Nearest Neighbors\n",
    "\n",
    "We will use fast ANN [IVFFlat algorithm](https://developer.nvidia.com/blog/accelerated-vector-search-approximating-with-rapids-raft-ivf-flat/) from Rapids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb3f3d7-bbb6-4105-bb86-b08fabba4ca4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(_, _, knn_df) = rapids_knn_model.kneighbors(query_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f30473c-ff6e-438a-bbce-11f1b0080a48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 7: Collect and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ec6847c-3592-4645-aca1-0fc6d9e3ed0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('py4j').setLevel(logging.ERROR)\n",
    "\n",
    "result_df = (\n",
    "    knn_df\n",
    "    .withColumn(\"zipped\", F.explode(F.arrays_zip(F.col(\"indices\"), F.col(\"distances\"))))\n",
    "    .select(F.col(\"query_id\"), F.col(\"zipped.indices\").alias(\"id\"), F.col(\"zipped.distances\").alias(\"distance\"))\n",
    "    .join(df, on=\"id\", how=\"inner\")\n",
    "    .select(\"query_id\", \"id\", \"data\", \"distance\")\n",
    ")\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b4c5a10-efd1-4d2d-b141-33e486943862",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "The goal of this demo is to showcase two acceleration techniques: local (per node) embedding generation and approximate KNN. Compared to the original method, which relies on HTTP requests to the OpenAI model and CPU-based KNN, this approach is significantly more scalable and provides substantial acceleration, especially for large input datasets.\n",
    "\n",
    "Test Results on 10 T4 GPU nodes the approaches:\n",
    "\n",
    "![Sample Image](/files/tables/comparison.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2,
    "widgetLayout": []
   },
   "notebookName": "Quickstart - Custom Embeddings and Approximate KNN",
   "widgets": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "save_output": true,
  "synapse_widget": {
   "state": {
    "4bd0e60b-98ae-4bfe-98ee-6f0399ceb456": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "count",
        "categoryFieldKeys": [
         "0"
        ],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [
         "0"
        ]
       },
       "tableOptions": {},
       "type": "details"
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "Once upon a time",
         "1": [
          " there was a girl who had a dream of becoming a writer.\n\nShe started writing short stories"
         ]
        },
        {
         "0": "Hello my name is",
         "1": [
          "***** and I have a question about my cat\n\nHello, thank you for bringing your question to"
         ]
        },
        {
         "0": "The best code is code thats",
         "1": [
          " not there\n\nCommenting your code is important. Not only does it help you remember what you"
         ]
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "prompt",
         "type": "string"
        },
        {
         "key": "1",
         "name": "text",
         "type": "ArrayType(StringType,true)"
        }
       ],
       "truncated": false
      }
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
