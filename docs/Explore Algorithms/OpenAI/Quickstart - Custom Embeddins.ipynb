{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6166efcb-b7f8-424b-8015-cb646a764271",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Embedding Text with local (per node) NVIDIA TensorRT accelerator and GPU based Aproximate Nearest Neighbor (ANN)\n",
    "\n",
    "The demo extending existing [Azure OpenAI based demo](https://github.com/microsoft/SynapseML/blob/master/docs/Explore%20Algorithms/OpenAI/Quickstart%20-%20OpenAI%20Embedding%20and%20GPU%20based%20KNN.ipynb) when encoding is processed by OpenAI requests and KNN was using GPU based brute force search. This tutorial shows how to perform fast local embeddings using [multilingual E5 text embeddings](https://arxiv.org/abs/2402.05672) and fast aproximate Nearest Neighbor search using IVFFlat alcorithm. All tutorial stages accelerated by NVIDIA GPU using [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt) and [Spark Rapids ML](https://github.com/NVIDIA/spark-rapids-ml). The tutorial folder contains two benchmark notebooks to demonstrate advantages of the presented GPU based approach compare to [previos CPU based demo](https://github.com/microsoft/SynapseML/blob/master/docs/Explore%20Algorithms/OpenAI/Quickstart%20-%20OpenAI%20Embedding.ipynb)\n",
    "\n",
    "The key prerequisites for this quickstart include a working Azure OpenAI resource, and an Apache Spark cluster with SynapseML installed. We suggest creating a Synapse workspace, but currently the notebook was running on Databricks GPU based cluster using Standard_NC24ads_A100_v4 with 6 workers. Databricks Runtime was 13.3 LTS ML (includes Apache Spark 3.4.1, GPU, Scala 2.12) with related [init_script](https://github.com/microsoft/SynapseML/tree/master/tools/init_scripts) to install all required packages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0444a03d-a701-4f59-b1a1-c4addb797d07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 1: Prepare Environment\n",
    "\n",
    "It will imports required libraries and get initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d188d8ee-8913-4170-8d35-8490f833ae95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# Assuming 'deep-learning' is at the root of your Databricks Repo\n",
    "repo_path = '/Workspace/Repos/aspiridonov@nvidia.com/SynapseML-db1/deep-learning/src/main/python'\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "from synapse.ml.HuggingFaceSentenceEmbedder import HuggingFaceSentenceEmbedder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tritonclient.grpc')\n",
    "import logging\n",
    "logging.getLogger('py4j').setLevel(logging.ERROR)\n",
    "import mlflow\n",
    "import datetime\n",
    "import pytz\n",
    "from spark_rapids_ml.knn import ApproximateNearestNeighbors, ApproximateNearestNeighborsModel\n",
    "\n",
    "logging.getLogger('sentence_transformers.SentenceTransformer').setLevel(logging.ERROR)\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "# Define the PST timezone\n",
    "pst_timezone = pytz.timezone('US/Pacific')\n",
    "\n",
    "# Get the current time in UTC and convert it to PST\n",
    "current_start_time_utc = datetime.datetime.now(pytz.utc)\n",
    "current_time_pst = current_start_time_utc.astimezone(pst_timezone)\n",
    "\n",
    "print(\"Current time in PST:\", current_time_pst.strftime('%Y-%m-%d %H:%M:%S %Z%z'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22603456-4f44-4b3a-9751-9ca5231b799b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 2: Load Data\n",
    "\n",
    "In this demo we will explore a dataset of fine food reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0065427-a0d5-4867-8209-61969dc48082",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataTransformer = HuggingFaceSentenceEmbedder(inputCol=\"combined\", outputCol=\"embeddings\", useTRTFlag=True, batchSize=16)\n",
    "\n",
    "# Load food revies with limiting number of rows until 1000000\n",
    "df = dataTransformer.load_data_food_reviews(spark=spark, limit=100).repartition(10).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c69ee56-172f-413b-a335-d15482fda55e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 3: Generate Embeddings\n",
    "\n",
    "We will first generate embeddings using NVIDIA TensorRT optimized SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d7bd9db-79a1-4d46-a849-ac49c3de7b49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_embeddings = dataTransformer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6885033f-6eea-4338-a632-2837582d91a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 4: Build the query against embeddings\n",
    "\n",
    "Get query embeddings running standard SentenceTransformer just on the driver. Convert embedding results to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b83621-3f42-42ff-847e-97a4af2d3276",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample queries\n",
    "queries = [\"desserts\", \"disgusting\"]\n",
    "\n",
    "# Create an instance of the EmbeddingTransformer to encode embeddings on drive only\n",
    "# to speed it up processing small amout of queries\n",
    "#embedding_transformer = EmbeddingTransformer(driverOnly=True, spark=spark)\n",
    "embedding_transformer = HuggingFaceSentenceEmbedder(driverOnly=True)\n",
    "query_embeddings = embedding_transformer.transform(queries, spark=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0154ce06-5875-4236-8178-030d45091445",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 5: Build a fast vector index to over review embeddings\n",
    "\n",
    "We will use fast NVIDIA Rapids indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa0e4178-75e4-412b-940e-25d55b7396ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rapids_knn = ApproximateNearestNeighbors(k=5)\n",
    "rapids_knn.setInputCol(\"embeddings\").setIdCol(\"id\")\n",
    "\n",
    "rapids_knn_model = rapids_knn.fit(all_embeddings.select(\"id\", \"embeddings\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "521c9c8e-6422-49c7-95f3-6bca44a90cbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 6: Find top k Nearest Neighbors\n",
    "\n",
    "We will use fast ANN IVFFlat algorithm from Rapids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb3f3d7-bbb6-4105-bb86-b08fabba4ca4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(_, _, knn_df) = rapids_knn_model.kneighbors(query_embeddings.select(\"id\", \"embeddings\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f30473c-ff6e-438a-bbce-11f1b0080a48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 7: Collect and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c3cb089-64fd-4089-b45c-4d1671d2c500",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(knn_df)\n",
    "\n",
    "print(f\"Demo finished\")\n",
    "\n",
    "# Get the current time in UTC and convert it to PST\n",
    "current_end_time_utc = datetime.datetime.now(pytz.utc)\n",
    "current_time_pst = current_end_time_utc.astimezone(pst_timezone)\n",
    "\n",
    "print(\"Current time in PST:\", current_time_pst.strftime('%Y-%m-%d %H:%M:%S %Z%z'))\n",
    "\n",
    "dif = current_end_time_utc - current_start_time_utc\n",
    "\n",
    "# Extract hours, minutes, and seconds from the difference\n",
    "total_seconds = int(dif.total_seconds())\n",
    "hours, remainder = divmod(total_seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "# Print the difference in the desired format\n",
    "print(f\"Difference: h: {hours}, min: {minutes}, sec: {seconds}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2,
    "widgetLayout": []
   },
   "notebookName": "Quickstart - Custom Embeddins",
   "widgets": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "save_output": true,
  "synapse_widget": {
   "state": {
    "4bd0e60b-98ae-4bfe-98ee-6f0399ceb456": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "count",
        "categoryFieldKeys": [
         "0"
        ],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [
         "0"
        ]
       },
       "tableOptions": {},
       "type": "details"
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "Once upon a time",
         "1": [
          " there was a girl who had a dream of becoming a writer.\n\nShe started writing short stories"
         ]
        },
        {
         "0": "Hello my name is",
         "1": [
          "***** and I have a question about my cat\n\nHello, thank you for bringing your question to"
         ]
        },
        {
         "0": "The best code is code thats",
         "1": [
          " not there\n\nCommenting your code is important. Not only does it help you remember what you"
         ]
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "prompt",
         "type": "string"
        },
        {
         "key": "1",
         "name": "text",
         "type": "ArrayType(StringType,true)"
        }
       ],
       "truncated": false
      }
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
